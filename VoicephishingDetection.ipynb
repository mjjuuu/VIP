{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KctjwfrZTsw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2805d9f7-97ca-48f2-9e90-749b5b6a0e2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 구글드라이브연동\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 작업디렉토리 설정 (voicephishing1폴더)\n",
        "import os\n",
        "\n",
        "# 작업할 디렉토리 설정\n",
        "work_dir = '/content/drive/My Drive/voicephishingDetection'\n",
        "\n",
        "# 작업 디렉토리로 이동\n",
        "os.chdir(work_dir)\n",
        "\n",
        "# 현재 작업 디렉토리 확인\n",
        "print(\"현재 작업 디렉토리:\", os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLu1r2rTVeYd",
        "outputId": "333b53a3-89b9-4989-8228-239942bb7274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 작업 디렉토리: /content/drive/My Drive/voicephishingDetection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7차 lstm학습코드 -> 시퀀스 30으로 제한 train_data.csv , test_data.csv, val_data.csv파일로 사전에 나눔. (label밸런싱, call_id기준으로 적용)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# -------------------------\n",
        "# 1. 학습 데이터 로딩 및 전처리\n",
        "# -------------------------\n",
        "train_df = pd.read_csv('train_data.csv', encoding='utf-8')\n",
        "\n",
        "train_texts = train_df['transcript'].astype(str).values\n",
        "train_labels = train_df['label'].values\n",
        "\n",
        "# -------------------------\n",
        "# 2. 검증 데이터 로딩 및 전처리\n",
        "# -------------------------\n",
        "valid_df = pd.read_csv('val_data.csv', encoding='utf-8')\n",
        "\n",
        "valid_texts = valid_df['transcript'].astype(str).values\n",
        "valid_labels = valid_df['label'].values\n",
        "\n",
        "# -------------------------\n",
        "# 3. 토크나이저 및 시퀀스 변환 (train 기준으로 학습)\n",
        "# -------------------------\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "\n",
        "X_train = pad_sequences(tokenizer.texts_to_sequences(train_texts), maxlen=30, padding='post', truncating='post')\n",
        "y_train = np.array(train_labels)\n",
        "\n",
        "X_valid = pad_sequences(tokenizer.texts_to_sequences(valid_texts), maxlen=30, padding='post', truncating='post')\n",
        "y_valid = np.array(valid_labels)\n",
        "\n",
        "# -------------------------\n",
        "# 4. LSTM 모델 구성\n",
        "# -------------------------\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=10000, output_dim=128, input_length=30))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# -------------------------\n",
        "# 5. 모델 학습 (validation 포함)\n",
        "# -------------------------\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_valid, y_valid))\n",
        "\n",
        "# -------------------------\n",
        "# 6. tokenizer, 모델 저장\n",
        "# -------------------------\n",
        "with open('/content/drive/MyDrive/voicephishingDetection/tokenizer0514.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "model.save('/content/drive/MyDrive/voicephishingDetection/lstm_model0514.keras')\n",
        "\n",
        "print(\"✅ 모델 학습 및 검증 완료, 저장도 완료\")\n",
        "\n",
        "# -------------------------\n",
        "# 7. 검증 데이터 성능 출력\n",
        "# -------------------------\n",
        "val_loss, val_acc = model.evaluate(X_valid, y_valid)\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xa4rNAEY79j",
        "outputId": "b1981aa2-19e8-46a8-d042-35d49d33e251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 119ms/step - accuracy: 0.8942 - loss: 0.2282 - val_accuracy: 0.9921 - val_loss: 0.0261\n",
            "Epoch 2/5\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 115ms/step - accuracy: 0.9941 - loss: 0.0200 - val_accuracy: 0.9903 - val_loss: 0.0246\n",
            "Epoch 3/5\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 117ms/step - accuracy: 0.9964 - loss: 0.0110 - val_accuracy: 0.9803 - val_loss: 0.0358\n",
            "Epoch 4/5\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 111ms/step - accuracy: 0.9963 - loss: 0.0114 - val_accuracy: 0.9918 - val_loss: 0.0221\n",
            "Epoch 5/5\n",
            "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 108ms/step - accuracy: 0.9984 - loss: 0.0057 - val_accuracy: 0.9907 - val_loss: 0.0227\n",
            "✅ 모델 학습 및 검증 완료, 저장도 완료\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9889 - loss: 0.0188\n",
            "Validation Accuracy: 0.9907\n",
            "Validation Loss: 0.0227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 라벨 분포 확인\n",
        "print(valid_df['label'].value_counts())\n",
        "\n",
        "# call_id 겹치는지 확인\n",
        "train_ids = set(train_df['call_id'].unique())\n",
        "valid_ids = set(valid_df['call_id'].unique())\n",
        "print(\"겹치는 call_id 수:\", len(train_ids & valid_ids))"
      ],
      "metadata": {
        "id": "TJacRRmqY9oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7차 lstm학습모델 검증 -> test_data.csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# -------------------------------\n",
        "# 1. 테스트 데이터 로딩\n",
        "# -------------------------------\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/voicephishing1/test_data.csv', encoding='utf-8-sig')\n",
        "test_texts = test_df['transcript'].astype(str).values\n",
        "test_labels = test_df['label'].values\n",
        "call_ids = test_df['call_id'].values  # call_id 추가\n",
        "\n",
        "# -------------------------------\n",
        "# 2. 저장된 Tokenizer 로드\n",
        "# -------------------------------\n",
        "with open('/content/drive/MyDrive/voicephishing1/tokenizer0514.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. 텍스트 → 시퀀스 변환 및 패딩\n",
        "# -------------------------------\n",
        "X_test = tokenizer.texts_to_sequences(test_texts)\n",
        "X_test = pad_sequences(X_test, maxlen=30, truncating='post', padding='post')\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. 저장된 모델 로드\n",
        "# -------------------------------\n",
        "model = load_model('/content/drive/MyDrive/voicephishing1/lstm_model0514.keras')\n",
        "\n",
        "# -------------------------------\n",
        "# 5. 개별 문장의 예측값 (확률) 구하기\n",
        "# -------------------------------\n",
        "predictions = model.predict(X_test)  # 예측값 (0과 1 사이의 확률)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. call_id별로 예측 확률의 평균값 계산\n",
        "# -------------------------------\n",
        "test_df['prediction'] = predictions  # 예측 확률을 DataFrame에 추가\n",
        "\n",
        "# call_id별로 평균 예측 확률 계산 (각 통화마다 평균 확률)\n",
        "call_id_avg_predictions = test_df.groupby('call_id')['prediction'].mean()\n",
        "\n",
        "# -------------------------------\n",
        "# 7. 각 통화에 대해 보이스피싱 여부 판단\n",
        "# -------------------------------\n",
        "# 예: 평균 확률이 0.5 이상이면 피싱 통화로 판단\n",
        "call_id_avg_predictions = call_id_avg_predictions.apply(lambda x: 1 if x >= 0.5 else 0)\n",
        "\n",
        "# -------------------------------\n",
        "# 8. 전체 성능 평가 (전체 통화 기준으로 평가)\n",
        "# -------------------------------\n",
        "# 테스트셋의 실제 라벨과 예측 라벨을 비교\n",
        "true_labels = test_df.groupby('call_id')['label'].first()  # 통화별 첫 번째 라벨로 참값 선택\n",
        "pred_labels = call_id_avg_predictions  # 통화별 예측값\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# 성능 평가 지표 출력\n",
        "accuracy = accuracy_score(true_labels, pred_labels)\n",
        "precision = precision_score(true_labels, pred_labels)\n",
        "recall = recall_score(true_labels, pred_labels)\n",
        "f1 = f1_score(true_labels, pred_labels)\n",
        "\n",
        "print(f\"✅ 정확도: {accuracy:.4f}\")\n",
        "print(f\"✅ 정밀도: {precision:.4f}\")\n",
        "print(f\"✅ 재현율: {recall:.4f}\")\n",
        "print(f\"✅ F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "4ICJVerCZMIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7차 lstm학습모델 과적합 여부 판단 1\n",
        "import random\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# 모델과 Tokenizer 로딩\n",
        "def load_model_and_tokenizer():\n",
        "    # LSTM 모델과 Tokenizer 로드\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/voicephishing1/lstm_model0514.keras')\n",
        "    with open('/content/drive/MyDrive/voicephishing1/tokenizer0514.pkl', 'rb') as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "    return model, tokenizer\n",
        "\n",
        "# 기존 데이터 복사\n",
        "test_df_flipped = test_df.copy()\n",
        "\n",
        "# 통화(call_id) 단위로 라벨 일부 뒤집기 (예: 10%)\n",
        "call_ids = test_df_flipped['call_id'].unique()\n",
        "num_to_flip = max(1, int(len(call_ids) * 0.1))\n",
        "flipped_call_ids = random.sample(list(call_ids), num_to_flip)\n",
        "\n",
        "# call_id 단위로 라벨 반전\n",
        "for cid in flipped_call_ids:\n",
        "    original_label = test_df_flipped.loc[test_df_flipped['call_id'] == cid, 'label'].iloc[0]\n",
        "    test_df_flipped.loc[test_df_flipped['call_id'] == cid, 'label'] = 1 - original_label\n",
        "\n",
        "print(f\"🔄 라벨 뒤집은 통화 수: {num_to_flip}\")\n",
        "\n",
        "# -------------------------------\n",
        "# 1. 모델과 Tokenizer 로드\n",
        "# -------------------------------\n",
        "model, tokenizer = load_model_and_tokenizer()\n",
        "\n",
        "# -------------------------------\n",
        "# 2. 라벨 반전된 데이터에 대해 예측 (각 통화별로)\n",
        "# -------------------------------\n",
        "# test_df_flipped에서 'call_id'별로 음성 텍스트를 처리하여 예측\n",
        "flipped_texts = test_df_flipped['transcript'].astype(str).values\n",
        "X_flipped = tokenizer.texts_to_sequences(flipped_texts)\n",
        "X_flipped = pad_sequences(X_flipped, maxlen=30, truncating='post', padding='post')\n",
        "\n",
        "# 예측값 (0과 1 사이의 확률)\n",
        "flipped_predictions = model.predict(X_flipped)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. call_id별로 예측 확률의 평균값 계산\n",
        "# -------------------------------\n",
        "test_df_flipped['prediction'] = flipped_predictions  # 예측 확률을 DataFrame에 추가\n",
        "call_id_avg_predictions_flipped = test_df_flipped.groupby('call_id')['prediction'].mean()\n",
        "\n",
        "# -------------------------------\n",
        "# 4. call_id별로 라벨 반전 후 예측값 평가\n",
        "# -------------------------------\n",
        "# 다시 그룹핑 및 평가\n",
        "true_labels_flipped = test_df_flipped.groupby('call_id')['label'].first()  # 통화별 첫 번째 라벨로 참값 선택\n",
        "pred_labels_flipped = call_id_avg_predictions_flipped.apply(lambda x: 1 if x >= 0.5 else 0)  # 0.5 이상이면 피싱 통화로 판단\n",
        "\n",
        "# 성능 평가 지표 출력\n",
        "accuracy = accuracy_score(true_labels_flipped, pred_labels_flipped)\n",
        "precision = precision_score(true_labels_flipped, pred_labels_flipped)\n",
        "recall = recall_score(true_labels_flipped, pred_labels_flipped)\n",
        "f1 = f1_score(true_labels_flipped, pred_labels_flipped)\n",
        "\n",
        "print(\"\\n✅ [라벨 반전 테스트]\")\n",
        "print(f\"정확도: {accuracy:.4f}\")\n",
        "print(f\"정밀도: {precision:.4f}\")\n",
        "print(f\"재현율: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "cktjrH6vZPSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7차 lstm학습모델 과적합 여부 판단 2\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 모델과 Tokenizer 로딩 함수\n",
        "def load_model_and_tokenizer():\n",
        "    # LSTM 모델과 Tokenizer 로드\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/voicephishing1/lstm_model0514.keras')\n",
        "    with open('/content/drive/MyDrive/voicephishing1/tokenizer0514.pkl', 'rb') as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "    return model, tokenizer\n",
        "\n",
        "# 텍스트 섞기 함수\n",
        "def shuffle_words(text):\n",
        "    words = text.split()\n",
        "    if len(words) > 1:\n",
        "        random.shuffle(words)\n",
        "    return ' '.join(words)\n",
        "\n",
        "# 모델과 Tokenizer 로드\n",
        "model, tokenizer = load_model_and_tokenizer()\n",
        "\n",
        "# 테스트 데이터 복사 및 텍스트 일부 랜덤 변경\n",
        "test_df_perturbed = test_df.copy()\n",
        "perturb_rate = 0.1  # 10%만 섞기\n",
        "\n",
        "# 텍스트 섞기\n",
        "indices_to_perturb = random.sample(range(len(test_df_perturbed)), int(len(test_df_perturbed) * perturb_rate))\n",
        "test_df_perturbed.loc[indices_to_perturb, 'transcript'] = test_df_perturbed.loc[indices_to_perturb, 'transcript'].apply(shuffle_words)\n",
        "\n",
        "# 텍스트 시퀀스 변환 및 패딩\n",
        "X_perturbed = tokenizer.texts_to_sequences(test_df_perturbed['transcript'].astype(str).values)\n",
        "X_perturbed = pad_sequences(X_perturbed, maxlen=30, truncating='post', padding='post')\n",
        "\n",
        "# 예측\n",
        "perturbed_predictions = model.predict(X_perturbed)\n",
        "test_df_perturbed['prediction'] = perturbed_predictions\n",
        "\n",
        "# 통화별 평균 예측값 계산\n",
        "perturbed_call_avg = test_df_perturbed.groupby('call_id')['prediction'].mean()\n",
        "perturbed_call_avg = perturbed_call_avg.apply(lambda x: 1 if x >= 0.5 else 0)\n",
        "\n",
        "# 평가\n",
        "true_labels = test_df_perturbed.groupby('call_id')['label'].first()\n",
        "pred_labels = perturbed_call_avg\n",
        "\n",
        "accuracy = accuracy_score(true_labels, pred_labels)\n",
        "precision = precision_score(true_labels, pred_labels)\n",
        "recall = recall_score(true_labels, pred_labels)\n",
        "f1 = f1_score(true_labels, pred_labels)\n",
        "\n",
        "print(\"\\n✅ [텍스트 섞기 테스트]\")\n",
        "print(f\"정확도: {accuracy:.4f}\")\n",
        "print(f\"정밀도: {precision:.4f}\")\n",
        "print(f\"재현율: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "OdxqrFskZROd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper"
      ],
      "metadata": {
        "id": "SCDFbk1nbJrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 7차 lstm학습모델 그놈목소리 수사기관 사칭형 mp3파일 테스트 (음성 시간 분할 없이 테스트)\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "import whisper\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "\n",
        "# -------------------------------\n",
        "# 1. mp3 -> wav 변환\n",
        "# -------------------------------\n",
        "def mp3_to_wav(mp3_file_path, wav_file_path):\n",
        "    audio = AudioSegment.from_mp3(mp3_file_path)\n",
        "    audio.export(wav_file_path, format=\"wav\")\n",
        "    print(f\"MP3 파일이 {wav_file_path}로 변환되었습니다.\")\n",
        "    return wav_file_path\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Whisper로 음성 인식 (STT)\n",
        "# -------------------------------\n",
        "def transcribe_audio_with_whisper(wav_file_path):\n",
        "    model = whisper.load_model(\"large\")  # Whisper의 모델 로드\n",
        "    result = model.transcribe(wav_file_path)\n",
        "    print(f\"음성 인식 결과: {result['text']}\")\n",
        "    return result['text']\n",
        "\n",
        "# -------------------------------\n",
        "# 3. 텍스트 처리 (Tokenizer 로딩, 시퀀스 변환 및 패딩)\n",
        "# -------------------------------\n",
        "def preprocess_text(text, tokenizer, max_length=30):\n",
        "    sequences = tokenizer.texts_to_sequences([text])\n",
        "    padded_sequence = pad_sequences(sequences, maxlen=max_length, truncating='post', padding='post')\n",
        "    return padded_sequence\n",
        "\n",
        "# -------------------------------\n",
        "# 4. LSTM 모델로 예측\n",
        "# -------------------------------\n",
        "def predict_with_lstm(model, text, tokenizer):\n",
        "    processed_text = preprocess_text(text, tokenizer)\n",
        "    prediction = model.predict(processed_text)\n",
        "    return prediction\n",
        "\n",
        "# -------------------------------\n",
        "# 5. 모델 및 Tokenizer 로딩\n",
        "# -------------------------------\n",
        "def load_model_and_tokenizer():\n",
        "    # LSTM 모델과 Tokenizer 로드\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/voicephishing1/lstm_model0514.keras')\n",
        "    with open('/content/drive/MyDrive/voicephishing1/tokenizer0514.pkl', 'rb') as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "    return model, tokenizer\n",
        "\n",
        "# -------------------------------\n",
        "# 6. MP3 파일 경로 지정 후 처리\n",
        "# -------------------------------\n",
        "def process_mp3(mp3_file_path):\n",
        "    # 1. mp3 파일을 wav로 변환\n",
        "    wav_file_path = mp3_to_wav(mp3_file_path, 'temp_audio.wav')\n",
        "\n",
        "    # 2. Whisper로 음성 인식 (STT)\n",
        "    transcribed_text = transcribe_audio_with_whisper(wav_file_path)\n",
        "\n",
        "    # 3. 모델과 Tokenizer 로드\n",
        "    model, tokenizer = load_model_and_tokenizer()\n",
        "\n",
        "    # 4. 예측\n",
        "    prediction = predict_with_lstm(model, transcribed_text, tokenizer)\n",
        "    print(f\"예측 결과 (피싱 통화 확률): {prediction[0][0]:.4f}\")\n",
        "\n",
        "    # 결과 반환\n",
        "    return transcribed_text, prediction\n",
        "\n",
        "# -------------------------------\n",
        "# 7. 예시: mp3 파일 처리\n",
        "# -------------------------------\n",
        "mp3_file_path = '/content/drive/MyDrive/voicephishing1/example.mp3'  # 처리할 mp3 파일 경로\n",
        "transcribed_text, prediction = process_mp3(mp3_file_path)\n",
        "print(f\"Transcribed Text: {transcribed_text}\")\n",
        "print(f\"Prediction: {prediction[0][0]:.4f}\")  # 예측 확률 출력\n"
      ],
      "metadata": {
        "id": "SLMb_aY1Ze3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 7차 lstm학습모델 그놈목소리 수사기관 사칭형 mp3파일 테스트 (음성 시간 분할 30초 설정 테스트)\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pydub import AudioSegment\n",
        "import whisper\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "\n",
        "# -------------------------------\n",
        "# 1. mp3 -> wav 변환\n",
        "# -------------------------------\n",
        "def mp3_to_wav(mp3_file_path, wav_file_path):\n",
        "    audio = AudioSegment.from_mp3(mp3_file_path)\n",
        "    audio.export(wav_file_path, format=\"wav\")\n",
        "    print(f\"MP3 파일이 {wav_file_path}로 변환되었습니다.\")\n",
        "    return wav_file_path\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Whisper로 음성 인식 (STT)\n",
        "# -------------------------------\n",
        "def transcribe_audio_with_whisper(wav_file_path, start_ms, duration_ms):\n",
        "    model = whisper.load_model(\"large\")  # Whisper의 모델 로드\n",
        "    audio = AudioSegment.from_wav(wav_file_path)\n",
        "    segment = audio[start_ms:start_ms + duration_ms]  # 구간별로 자르기\n",
        "    segment.export(\"temp_segment.wav\", format=\"wav\")\n",
        "\n",
        "    result = model.transcribe(\"temp_segment.wav\")\n",
        "    os.remove(\"temp_segment.wav\")  # 임시 파일 삭제\n",
        "    print(f\"음성 인식 결과 (구간 {start_ms / 1000}s - {(start_ms + duration_ms) / 1000}s): {result['text']}\")\n",
        "    return result['text']\n",
        "\n",
        "# -------------------------------\n",
        "# 3. 텍스트 처리 (Tokenizer 로딩, 시퀀스 변환 및 패딩)\n",
        "# -------------------------------\n",
        "def preprocess_text(text, tokenizer, max_length=30):\n",
        "    sequences = tokenizer.texts_to_sequences([text])\n",
        "    padded_sequence = pad_sequences(sequences, maxlen=max_length, truncating='post', padding='post')\n",
        "    return padded_sequence\n",
        "\n",
        "# -------------------------------\n",
        "# 4. LSTM 모델로 예측\n",
        "# -------------------------------\n",
        "def predict_with_lstm(model, text, tokenizer):\n",
        "    processed_text = preprocess_text(text, tokenizer)\n",
        "    prediction = model.predict(processed_text)\n",
        "    return prediction\n",
        "\n",
        "# -------------------------------\n",
        "# 5. 모델 및 Tokenizer 로딩\n",
        "# -------------------------------\n",
        "def load_model_and_tokenizer():\n",
        "    # LSTM 모델과 Tokenizer 로드\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/voicephishing1/lstm_model0514.keras')\n",
        "    with open('/content/drive/MyDrive/voicephishing1/tokenizer0514.pkl', 'rb') as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "    return model, tokenizer\n",
        "\n",
        "# -------------------------------\n",
        "# 6. MP3 파일 경로 지정 후 처리\n",
        "# -------------------------------\n",
        "def process_mp3(mp3_file_path, segment_duration_ms=20000):  # 20초 구간으로 변경\n",
        "    # 1. mp3 파일을 wav로 변환\n",
        "    wav_file_path = mp3_to_wav(mp3_file_path, 'temp_audio.wav')\n",
        "\n",
        "    # 2. 모델과 Tokenizer 로드\n",
        "    model, tokenizer = load_model_and_tokenizer()\n",
        "\n",
        "    # 3. 음성 파일의 총 길이 (밀리초 단위)\n",
        "    audio = AudioSegment.from_wav(wav_file_path)\n",
        "    total_length_ms = len(audio)\n",
        "\n",
        "    # 4. 예측 결과 저장할 리스트\n",
        "    time_intervals = []\n",
        "    predictions = []\n",
        "\n",
        "    # 5. 각 구간에 대해 Whisper로 음성 인식 후 예측 수행\n",
        "    for start_ms in range(0, total_length_ms, segment_duration_ms):\n",
        "        transcribed_text = transcribe_audio_with_whisper(wav_file_path, start_ms, segment_duration_ms)\n",
        "        prediction = predict_with_lstm(model, transcribed_text, tokenizer)\n",
        "        time_intervals.append(start_ms / 1000)  # 시간 (초 단위)\n",
        "        predictions.append(prediction[0][0])  # 예측 확률 저장\n",
        "\n",
        "    # 결과 반환\n",
        "    return time_intervals, predictions\n",
        "\n",
        "# -------------------------------\n",
        "# 7. 예시: mp3 파일 처리 및 예측 결과 그래프 출력\n",
        "# -------------------------------\n",
        "mp3_file_path = '/content/drive/MyDrive/voicephishing1/example.mp3'  # 처리할 mp3 파일 경로\n",
        "time_intervals, predictions = process_mp3(mp3_file_path)\n",
        "\n",
        "# 그래프 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(time_intervals, predictions, marker='o', color='b', linestyle='-', label='피싱 통화 확률')\n",
        "plt.title(\"시간에 따른 피싱 통화 확률\")\n",
        "plt.xlabel(\"시간 (초)\")\n",
        "plt.ylabel(\"피싱 통화 확률\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hAu3Fy5bZhe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "import whisper\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "\n",
        "# -------------------------------\n",
        "# 1. mp3 → wav 변환\n",
        "# -------------------------------\n",
        "def mp3_to_wav(mp3_file_path, wav_file_path):\n",
        "    audio = AudioSegment.from_mp3(mp3_file_path)\n",
        "    audio.export(wav_file_path, format=\"wav\")\n",
        "    print(f\"✅ MP3 → WAV 변환 완료: {wav_file_path}\")\n",
        "    return wav_file_path\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Whisper 음성 인식\n",
        "# -------------------------------\n",
        "def transcribe_audio_with_whisper(wav_file_path):\n",
        "    model = whisper.load_model(\"large\")\n",
        "    result = model.transcribe(wav_file_path)\n",
        "    print(\"\\n📝 음성 인식 결과:\")\n",
        "    print(result['text'])\n",
        "    return result['text']\n",
        "\n",
        "# -------------------------------\n",
        "# 3. 전처리 함수\n",
        "# -------------------------------\n",
        "def preprocess_text(text, tokenizer, max_length=30):\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # 문장부호 제거\n",
        "    sequences = tokenizer.texts_to_sequences([text])\n",
        "    padded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "    return padded\n",
        "\n",
        "# -------------------------------\n",
        "# 4. 예측 함수\n",
        "# -------------------------------\n",
        "def predict_with_lstm(model, text, tokenizer):\n",
        "    padded_text = preprocess_text(text, tokenizer)\n",
        "    prediction = model.predict(padded_text, verbose=0)\n",
        "    return prediction[0][0]\n",
        "\n",
        "# -------------------------------\n",
        "# 5. 모델 & 토크나이저 로딩\n",
        "# -------------------------------\n",
        "def load_model_and_tokenizer():\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/voicephishing1/lstm_model0514.keras')\n",
        "    with open('/content/drive/MyDrive/voicephishing1/tokenizer0514.pkl', 'rb') as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "    return model, tokenizer\n",
        "\n",
        "# -------------------------------\n",
        "# 6. 누적 위험도 계산 및 출력\n",
        "# -------------------------------\n",
        "def run_prediction_with_risk(text, model, tokenizer, base_threshold=0.5, detection_threshold=3.0):\n",
        "    print(\"\\n📊 누적 위험도 분석 시작\")\n",
        "    lines = [line.strip() for line in text.split('.') if line.strip()]  # 문장 분할\n",
        "    cumulative_risk = 0.0\n",
        "    phishing_detected_at = None\n",
        "    predictions = []\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        prob = predict_with_lstm(model, line, tokenizer)\n",
        "        predictions.append(prob)\n",
        "\n",
        "        if prob > base_threshold:\n",
        "            cumulative_risk += (prob - base_threshold)\n",
        "        else:\n",
        "            cumulative_risk = max(0, cumulative_risk - (base_threshold - prob))\n",
        "\n",
        "        print(f\"{i+1:02d}. \\\"{line}\\\" → 확률: {prob:.4f}, 누적 위험도: {cumulative_risk:.4f}\")\n",
        "\n",
        "        if phishing_detected_at is None and cumulative_risk >= detection_threshold:\n",
        "            phishing_detected_at = i * 10  # 시간 기준 10초 단위로 가정\n",
        "\n",
        "    if phishing_detected_at is not None:\n",
        "        print(f\"\\n⚠️ 보이스피싱 의심 탐지 시점: {phishing_detected_at}초\")\n",
        "    else:\n",
        "        print(\"\\n✅ 보이스피싱 의심 없음\")\n",
        "\n",
        "    return lines, predictions, phishing_detected_at\n",
        "\n",
        "# -------------------------------\n",
        "# 7. 시각화\n",
        "# -------------------------------\n",
        "def plot_predictions(lines, predictions, phishing_detected_at=None):\n",
        "    time_intervals = [i * 10 for i in range(len(lines))]\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(time_intervals, predictions, marker='o', linestyle='-', color='red', label='예측 확률')\n",
        "    plt.title(\"피싱 통화 확률 시각화\")\n",
        "    plt.xlabel(\"시간 (초)\")\n",
        "    plt.ylabel(\"피싱 통화 확률\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(True)\n",
        "\n",
        "    if phishing_detected_at is not None:\n",
        "        plt.axvline(x=phishing_detected_at, color='blue', linestyle='--', label='탐지 시점')\n",
        "        plt.text(phishing_detected_at + 1, 0.85, '⚠ 탐지됨', color='blue')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# 8. 전체 파이프라인 실행 함수\n",
        "# -------------------------------\n",
        "def process_mp3(mp3_file_path):\n",
        "    # 1. mp3 → wav\n",
        "    wav_file_path = mp3_to_wav(mp3_file_path, 'temp_audio.wav')\n",
        "\n",
        "    # 2. whisper로 음성 인식\n",
        "    transcribed_text = transcribe_audio_with_whisper(wav_file_path)\n",
        "\n",
        "    # 3. 모델 및 토크나이저 로딩\n",
        "    model, tokenizer = load_model_and_tokenizer()\n",
        "\n",
        "    # 4. 예측 및 누적 위험도 분석\n",
        "    lines, predictions, phishing_detected_at = run_prediction_with_risk(transcribed_text, model, tokenizer)\n",
        "\n",
        "    # 5. 시각화\n",
        "    plot_predictions(lines, predictions, phishing_detected_at)\n",
        "\n",
        "    return transcribed_text, predictions\n",
        "\n",
        "# -------------------------------\n",
        "# 9. 실행\n",
        "# -------------------------------\n",
        "mp3_file_path = '/content/drive/MyDrive/voicephishing1/example.mp3'\n",
        "transcribed_text, predictions = process_mp3(mp3_file_path)\n"
      ],
      "metadata": {
        "id": "gxxrSItAZkxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "import whisper\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "\n",
        "# -------------------------------\n",
        "# 1. mp3 → wav 변환\n",
        "# -------------------------------\n",
        "def mp3_to_wav(mp3_file_path, wav_file_path):\n",
        "    audio = AudioSegment.from_mp3(mp3_file_path)\n",
        "    audio.export(wav_file_path, format=\"wav\")\n",
        "    print(f\"✅ MP3 → WAV 변환 완료: {wav_file_path}\")\n",
        "    return wav_file_path\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Whisper 음성 인식\n",
        "# -------------------------------\n",
        "def transcribe_audio_with_whisper(wav_file_path):\n",
        "    model = whisper.load_model(\"large\")\n",
        "    result = model.transcribe(wav_file_path)\n",
        "    print(\"\\n📝 음성 인식 결과:\")\n",
        "    print(result['text'])\n",
        "    return result['text']\n",
        "\n",
        "# -------------------------------\n",
        "# 3. 전처리 함수\n",
        "# -------------------------------\n",
        "def preprocess_text(text, tokenizer, max_length=30):\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # 문장부호 제거\n",
        "    sequences = tokenizer.texts_to_sequences([text])\n",
        "    padded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "    return padded\n",
        "\n",
        "# -------------------------------\n",
        "# 4. 예측 함수\n",
        "# -------------------------------\n",
        "def predict_with_lstm(model, text, tokenizer):\n",
        "    padded_text = preprocess_text(text, tokenizer)\n",
        "    prediction = model.predict(padded_text, verbose=0)\n",
        "    return prediction[0][0]\n",
        "\n",
        "# -------------------------------\n",
        "# 5. 모델 & 토크나이저 로딩\n",
        "# -------------------------------\n",
        "def load_model_and_tokenizer():\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/voicephishing1/lstm_model0514.keras')\n",
        "    with open('/content/drive/MyDrive/voicephishing1/tokenizer0514.pkl', 'rb') as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "    return model, tokenizer\n",
        "\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 6. 누적 평균 기반 위험도 분석\n",
        "# -------------------------------\n",
        "def run_prediction_with_cumulative_average(text, model, tokenizer, threshold=0.7):\n",
        "    print(\"\\n📊 누적 평균 위험도 분석 시작\")\n",
        "    lines = [line.strip() for line in text.split('.') if line.strip()]  # 문장 분할\n",
        "    predictions = []\n",
        "    cumulative_sum = 0.0\n",
        "    phishing_detected_at = None\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        prob = predict_with_lstm(model, line, tokenizer)\n",
        "        predictions.append(prob)\n",
        "        cumulative_sum += prob\n",
        "        cumulative_avg = cumulative_sum / (i + 1)\n",
        "\n",
        "        print(f\"{i+1:02d}. \\\"{line}\\\" → 확률: {prob:.4f}, 누적 평균: {cumulative_avg:.4f}\")\n",
        "\n",
        "        if phishing_detected_at is None and cumulative_avg > threshold:\n",
        "            phishing_detected_at = i * 10  # 시간 단위 가정\n",
        "\n",
        "    if phishing_detected_at is not None:\n",
        "        print(f\"\\n⚠️ 보이스피싱 의심 탐지 시점: {phishing_detected_at}초 (누적 평균 기반)\")\n",
        "    else:\n",
        "        print(\"\\n✅ 보이스피싱 의심 없음\")\n",
        "\n",
        "    return lines, predictions, phishing_detected_at\n",
        "\n",
        "# -------------------------------\n",
        "# 7. 시각화 (변경 없음)\n",
        "# -------------------------------\n",
        "def plot_predictions(lines, predictions, phishing_detected_at=None):\n",
        "    time_intervals = [i * 10 for i in range(len(lines))]\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(time_intervals, predictions, marker='o', linestyle='-', color='red', label='예측 확률')\n",
        "    plt.title(\"피싱 통화 확률 시각화\")\n",
        "    plt.xlabel(\"시간 (초)\")\n",
        "    plt.ylabel(\"피싱 통화 확률\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(True)\n",
        "\n",
        "    if phishing_detected_at is not None:\n",
        "        plt.axvline(x=phishing_detected_at, color='blue', linestyle='--', label='탐지 시점')\n",
        "        plt.text(phishing_detected_at + 1, 0.85, '⚠ 탐지됨', color='blue')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# 8. 전체 파이프라인 실행 함수\n",
        "# -------------------------------\n",
        "def process_mp3(mp3_file_path):\n",
        "    # 1. mp3 → wav\n",
        "    wav_file_path = mp3_to_wav(mp3_file_path, 'temp_audio.wav')\n",
        "\n",
        "    # 2. whisper로 음성 인식\n",
        "    transcribed_text = transcribe_audio_with_whisper(wav_file_path)\n",
        "\n",
        "    # 3. 모델 및 토크나이저 로딩\n",
        "    model, tokenizer = load_model_and_tokenizer()\n",
        "\n",
        "    # 4. 예측 및 누적 평균 기반 분석\n",
        "    lines, predictions, phishing_detected_at = run_prediction_with_cumulative_average(\n",
        "        transcribed_text, model, tokenizer\n",
        "    )\n",
        "\n",
        "    # 5. 시각화\n",
        "    plot_predictions(lines, predictions, phishing_detected_at)\n",
        "\n",
        "    return transcribed_text, predictions\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 9. 실행\n",
        "# -------------------------------\n",
        "mp3_file_path = '/content/drive/MyDrive/voicephishing1/example.mp3'\n",
        "transcribed_text, predictions = process_mp3(mp3_file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "bCLI4AqhZsPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "import string\n",
        "\n",
        "# -------------------------------\n",
        "# 1. 텍스트 전처리\n",
        "# -------------------------------\n",
        "def preprocess_text(text, tokenizer, max_length=30):\n",
        "    sequences = tokenizer.texts_to_sequences([text])\n",
        "    padded_sequence = pad_sequences(sequences, maxlen=max_length, truncating='post', padding='post')\n",
        "    return padded_sequence\n",
        "\n",
        "# -------------------------------\n",
        "# 2. LSTM 예측\n",
        "# -------------------------------\n",
        "def predict_with_lstm(model, text, tokenizer):\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # 문장부호 제거\n",
        "    processed_text = preprocess_text(text, tokenizer)\n",
        "    prediction = model.predict(processed_text)\n",
        "    return prediction\n",
        "\n",
        "# -------------------------------\n",
        "# 3. 모델 및 Tokenizer 로딩\n",
        "# -------------------------------\n",
        "def load_model_and_tokenizer():\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/voicephishing/lstm_model0514.keras')\n",
        "    with open('/content/drive/MyDrive/voicephishing/tokenizer0514.pkl', 'rb') as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "    return model, tokenizer\n",
        "\n",
        "# -------------------------------\n",
        "# 4. 대화 스크립트 기반 처리\n",
        "# -------------------------------\n",
        "def process_script(script_lines):\n",
        "    model, tokenizer = load_model_and_tokenizer()\n",
        "    time_intervals = []\n",
        "    predictions = []\n",
        "\n",
        "    for i, line in enumerate(script_lines):\n",
        "        prediction = predict_with_lstm(model, line, tokenizer)\n",
        "        time_intervals.append(i * 10)  # 10초 간격 기준\n",
        "        predictions.append(prediction[0][0])\n",
        "        print(f\"{i+1:02d}. \\\"{line}\\\" → 예측 확률: {prediction[0][0]:.4f}\")\n",
        "\n",
        "    return time_intervals, predictions\n",
        "\n",
        "# -------------------------------\n",
        "# 5. 테스트할 보이스피싱인 척하는 대화 스크립트\n",
        "# -------------------------------\n",
        "script_lines = [\n",
        "    \"여보세요\",  # 피해자\n",
        "    \"고객님 맞으시죠\",  # 피싱범\n",
        "    \"네, 누구세요?\",  # 피해자\n",
        "    \"지금 잠깐 통화 가능하신가요\",  # 피싱범\n",
        "    \"네, 말씀하세요\",  # 피해자\n",
        "    \"저는 금융보호센터 상담팀에 있는 김수현이라고 합니다\",  # 피싱범\n",
        "    \"금융보호센터요?\",  # 피해자\n",
        "    \"다름이 아니라 고객님 명의로 개설된 계좌에서 최근 이상 거래가 감지돼서요\",  # 피싱범\n",
        "    \"이상 거래요?\",  # 피해자\n",
        "    \"혹시 오늘 오전에 휴대폰으로 이체하신 적 있으신가요\",  # 피싱범\n",
        "    \"아뇨 그런 적 없어요\",  # 피해자\n",
        "    \"확인해보니까 고객님 계좌에서 부산에서 접속한 기록이 떠서요\",  # 피싱범\n",
        "    \"저 부산에 없는데요\",  # 피해자\n",
        "    \"그럼 본인 확인만 간단하게 도와드릴게요\",  # 피싱범\n",
        "    \"어떻게 해요?\",  # 피해자\n",
        "    \"은행은 국민은행 사용하고 계시죠\",  # 피싱범\n",
        "    \"네\",  # 피해자\n",
        "    \"다른 건 필요 없고요\",  # 피싱범\n",
        "    \"이름이랑 계좌번호 앞 네자리만 말씀해주시면 됩니다\",  # 피싱범\n",
        "    \"홍길동, 1234요\",  # 피해자 (예시)\n",
        "    \"네 확인되었습니다\",  # 피싱범\n",
        "    \"지금 바로 보호조치 들어가고 있으니까요\",  # 피싱범\n",
        "    \"잠시 후에 인증번호가 문자로 갈 텐데\",  # 피싱범\n",
        "    \"받으시는 대로 그 번호만 다시 말씀해주세요\",  # 피싱범\n",
        "    \"아 네 알겠습니다\",  # 피해자\n",
        "    \"절차 끝나면 자동으로 보호조치 완료됩니다\",  # 피싱범\n",
        "    \"감사합니다\",  # 피해자\n",
        "    \"불편드려 죄송합니다\",  # 피싱범\n",
        "]\n",
        "\n",
        "# -------------------------------\n",
        "# 6. 처리 및 시각화\n",
        "# -------------------------------\n",
        "time_intervals, predictions = process_script(script_lines)\n",
        "\n",
        "# [수정 1] 0초에서 0을 추가하여 그래프가 0,0에서 시작하도록 만듦\n",
        "time_intervals = [0] + [t + 10 for t in time_intervals]\n",
        "predictions = [0] + predictions\n",
        "\n",
        "# [수정 2] x축 눈금을 10초 단위로 모두 표시\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(time_intervals, predictions, marker='o', color='r', linestyle='-', label='피싱 통화 확률')\n",
        "plt.title(\"스크립트에 따른 피싱 통화 확률\")\n",
        "plt.xlabel(\"시간 (초)\")\n",
        "plt.ylabel(\"피싱 통화 확률\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.xticks(np.arange(0, max(time_intervals) + 10, 10))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_JfuPGd9ZvI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "import string\n",
        "\n",
        "# -------------------------------\n",
        "# 1. 텍스트 전처리\n",
        "# -------------------------------\n",
        "def preprocess_text(text, tokenizer, max_length=30):\n",
        "    sequences = tokenizer.texts_to_sequences([text])\n",
        "    padded_sequence = pad_sequences(sequences, maxlen=max_length, truncating='post', padding='post')\n",
        "    return padded_sequence\n",
        "\n",
        "# -------------------------------\n",
        "# 2. LSTM 예측\n",
        "# -------------------------------\n",
        "def predict_with_lstm(model, text, tokenizer):\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # 문장부호 제거\n",
        "    processed_text = preprocess_text(text, tokenizer)\n",
        "    prediction = model.predict(processed_text, verbose=0)\n",
        "    return prediction\n",
        "\n",
        "# -------------------------------\n",
        "# 3. 모델 및 Tokenizer 로딩\n",
        "# -------------------------------\n",
        "def load_model_and_tokenizer():\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/voicephishing1/lstm_model0514.keras')\n",
        "    with open('/content/drive/MyDrive/voicephishing1/tokenizer0514.pkl', 'rb') as f:\n",
        "        tokenizer = pickle.load(f)\n",
        "    return model, tokenizer\n",
        "\n",
        "# -------------------------------\n",
        "# 4. 대화 스크립트 기반 처리 (누적 위험도 포함)\n",
        "# -------------------------------\n",
        "def process_script(script_lines, base_threshold=0.5, detection_threshold=3.0):\n",
        "    model, tokenizer = load_model_and_tokenizer()\n",
        "    time_intervals = []\n",
        "    predictions = []\n",
        "    cumulative_risk = 0.0\n",
        "    phishing_detected_at = None\n",
        "\n",
        "    print(\"\\n[예측 결과 및 누적 위험도]\\n\")\n",
        "    for i, line in enumerate(script_lines):\n",
        "        prediction = predict_with_lstm(model, line, tokenizer)\n",
        "        prob = prediction[0][0]\n",
        "        predictions.append(prob)\n",
        "        time_intervals.append(i * 10)\n",
        "\n",
        "        # 누적 위험도 계산\n",
        "        if prob > base_threshold:\n",
        "            cumulative_risk += (prob - base_threshold)\n",
        "        else:\n",
        "            cumulative_risk = max(0, cumulative_risk - (base_threshold - prob))\n",
        "\n",
        "        print(f\"{i+1:02d}. \\\"{line}\\\" → 확률: {prob:.4f}, 누적 위험도: {cumulative_risk:.4f}\")\n",
        "\n",
        "        if phishing_detected_at is None and cumulative_risk >= detection_threshold:\n",
        "            phishing_detected_at = i * 10\n",
        "\n",
        "    if phishing_detected_at is not None:\n",
        "        print(f\"\\n⚠️ 보이스피싱 의심 탐지 시점: {phishing_detected_at}초\")\n",
        "    else:\n",
        "        print(\"\\n✅ 보이스피싱 의심되지 않음\")\n",
        "\n",
        "    return time_intervals, predictions, phishing_detected_at\n",
        "\n",
        "# -------------------------------\n",
        "# 5. 테스트할 대화 스크립트\n",
        "# -------------------------------\n",
        "script_lines = [\n",
        "    \"여보세요\",  # 피해자\n",
        "    \"고객님 맞으시죠\",  # 피싱범\n",
        "    \"네, 누구세요?\",  # 피해자\n",
        "    \"지금 잠깐 통화 가능하신가요\",  # 피싱범\n",
        "    \"네, 말씀하세요\",  # 피해자\n",
        "    \"저는 금융보호센터 상담팀에 있는 김수현이라고 합니다\",  # 피싱범\n",
        "    \"금융보호센터요?\",  # 피해자\n",
        "    \"다름이 아니라 고객님 명의로 개설된 계좌에서 최근 이상 거래가 감지돼서요\",  # 피싱범\n",
        "    \"이상 거래요?\",  # 피해자\n",
        "    \"혹시 오늘 오전에 휴대폰으로 이체하신 적 있으신가요\",  # 피싱범\n",
        "    \"아뇨 그런 적 없어요\",  # 피해자\n",
        "    \"확인해보니까 고객님 계좌에서 부산에서 접속한 기록이 떠서요\",  # 피싱범\n",
        "    \"저 부산에 없는데요\",  # 피해자\n",
        "    \"그럼 본인 확인만 간단하게 도와드릴게요\",  # 피싱범\n",
        "    \"어떻게 해요?\",  # 피해자\n",
        "    \"은행은 국민은행 사용하고 계시죠\",  # 피싱범\n",
        "    \"네\",  # 피해자\n",
        "    \"다른 건 필요 없고요\",  # 피싱범\n",
        "    \"이름이랑 계좌번호 앞 네자리만 말씀해주시면 됩니다\",  # 피싱범\n",
        "    \"홍길동, 1234요\",  # 피해자 (예시)\n",
        "    \"네 확인되었습니다\",  # 피싱범\n",
        "    \"지금 바로 보호조치 들어가고 있으니까요\",  # 피싱범\n",
        "    \"잠시 후에 인증번호가 문자로 갈 텐데\",  # 피싱범\n",
        "    \"받으시는 대로 그 번호만 다시 말씀해주세요\",  # 피싱범\n",
        "    \"아 네 알겠습니다\",  # 피해자\n",
        "    \"절차 끝나면 자동으로 보호조치 완료됩니다\",  # 피싱범\n",
        "    \"감사합니다\",  # 피해자\n",
        "    \"불편드려 죄송합니다\",  # 피싱범\n",
        "]\n",
        "\n",
        "# -------------------------------\n",
        "# 6. 처리 및 시각화\n",
        "# -------------------------------\n",
        "time_intervals, predictions, phishing_detected_at = process_script(script_lines)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(time_intervals, predictions, marker='o', color='r', linestyle='-', label='피싱 통화 확률')\n",
        "plt.title(\"스크립트에 따른 피싱 통화 확률\")\n",
        "plt.xlabel(\"시간 (초)\")\n",
        "plt.ylabel(\"피싱 통화 확률\")\n",
        "plt.grid(True)\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "# 탐지 시점 시각화\n",
        "if phishing_detected_at is not None:\n",
        "    plt.axvline(x=phishing_detected_at, color='blue', linestyle='--', label='탐지 시점')\n",
        "    plt.text(phishing_detected_at + 1, 0.9, '⚠ 탐지됨', color='blue')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1KLE2uZ-Z5sk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}